#!/bin/bash

echo "ðŸš€ Instalando Ollama para modelos locales..."

# Descargar e instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar instalaciÃ³n
ollama --version

echo "âœ… Ollama instalado correctamente"
echo ""
echo "ðŸ“¥ Descargando modelos recomendados..."

# Descargar modelos populares (puedes comentar los que no necesites)
echo "Descargando Llama 3.2 (3B) - Modelo rÃ¡pido y eficiente..."
ollama pull llama3.2:3b

echo "Descargando Llama 3.2 (1B) - Modelo muy ligero..."
ollama pull llama3.2:1b

echo "Descargando Qwen2.5 (7B) - Excelente modelo multilingÃ¼e..."
ollama pull qwen2.5:7b

echo "Descargando CodeLlama (7B) - Especializado en cÃ³digo..."
ollama pull codellama:7b

echo ""
echo "ðŸŽ‰ Modelos descargados exitosamente!"
echo ""
echo "ðŸ”§ Para usar con OpenWebUI:"
echo "1. AsegÃºrate de que Ollama estÃ© ejecutÃ¡ndose: ollama serve"
echo "2. En OpenWebUI, los modelos aparecerÃ¡n automÃ¡ticamente"
echo ""
echo "ðŸ“‹ Modelos disponibles:"
ollama list