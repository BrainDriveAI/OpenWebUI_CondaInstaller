# üéâ INSTALACI√ìN COMPLETA DE OPENWEBUI CON MODELOS

## ‚úÖ ESTADO: INSTALACI√ìN EXITOSA Y FUNCIONAL

### üöÄ Servicios Ejecut√°ndose:

1. **OpenWebUI** ‚úÖ
   - Puerto: 12000
   - URL: https://work-1-pmibcoomalqbelgr.prod-runtime.all-hands.dev
   - Estado: Funcionando perfectamente

2. **Ollama** ‚úÖ
   - Puerto: 11434
   - Estado: Ejecut√°ndose con modelos cargados
   - Conexi√≥n con OpenWebUI: Configurada autom√°ticamente

### ü§ñ Modelos de IA Instalados:

1. **Llama 3.2 1B** (1.3 GB)
   - Ultraligero y r√°pido
   - Ideal para pruebas y chat b√°sico

2. **Llama 3.2 3B** (2.0 GB)
   - Equilibrado entre velocidad y calidad
   - Recomendado para uso general

### üìÅ Archivos Creados:

- `start_openwebui.sh` - Script para iniciar OpenWebUI
- `instalar_ollama.sh` - Script de instalaci√≥n de Ollama
- `descargar_modelos.sh` - Script interactivo para descargar m√°s modelos
- `GUIA_INSTALACION_OPENWEBUI.md` - Gu√≠a completa de instalaci√≥n
- `GUIA_MODELOS_OPENWEBUI.md` - Gu√≠a completa de modelos
- `openwebui.log` - Log del servidor OpenWebUI
- `ollama.log` - Log del servidor Ollama

## üéØ C√ìMO USAR AHORA:

### 1. Acceder a OpenWebUI:
```
URL: https://work-1-pmibcoomalqbelgr.prod-runtime.all-hands.dev
```

### 2. Crear Cuenta (Primera vez):
- Llenar formulario de registro
- Crear cuenta de administrador
- Los modelos aparecer√°n autom√°ticamente

### 3. Seleccionar Modelo:
- En la interfaz, buscar selector de modelos
- Elegir entre:
  - `llama3.2:1b` (r√°pido)
  - `llama3.2:3b` (equilibrado)

### 4. ¬°Comenzar a Chatear!

## üì• DESCARGAR M√ÅS MODELOS:

### M√©todo F√°cil (Script Interactivo):
```bash
./descargar_modelos.sh
```

### M√©todo Manual:
```bash
# Modelos ligeros recomendados
ollama pull phi3:mini          # 2.3GB - Microsoft
ollama pull gemma2:2b          # 1.6GB - Google

# Modelos medianos
ollama pull qwen2.5:7b         # 4.4GB - Multiling√ºe excelente
ollama pull codellama:7b       # 3.8GB - Para programaci√≥n

# Ver todos los modelos
ollama list
```

## üõ†Ô∏è COMANDOS √öTILES:

### Gesti√≥n de Servicios:
```bash
# Verificar que todo est√° ejecut√°ndose
ps aux | grep -E "(ollama|open-webui)"

# Iniciar OpenWebUI (si se detiene)
./start_openwebui.sh

# Iniciar Ollama (si se detiene)
ollama serve &

# Ver logs
tail -f openwebui.log
tail -f ollama.log
```

### Gesti√≥n de Modelos:
```bash
# Listar modelos instalados
ollama list

# Probar un modelo
ollama run llama3.2:3b "Hola, ¬øc√≥mo est√°s?"

# Eliminar un modelo
ollama rm [nombre_modelo]
```

## üåü MODELOS RECOMENDADOS POR CATEGOR√çA:

### üü¢ Para Empezar (Ya instalados):
- **llama3.2:1b** - Ultraligero, perfecto para empezar
- **llama3.2:3b** - Equilibrado, uso general

### üü° Para Mejor Calidad:
- **qwen2.5:7b** - Excelente multiling√ºe (espa√±ol muy bueno)
- **llama3.1:8b** - Premium, muy buena calidad

### üíª Para Programaci√≥n:
- **codellama:7b** - Especializado en c√≥digo
- **deepseek-coder:6.7b** - Excelente para desarrollo

### üåç Multiling√ºes:
- **qwen2.5:7b** - El mejor para espa√±ol
- **aya:8b** - Multiling√ºe de Cohere

## üîß CONFIGURACI√ìN AVANZADA:

### Variables de Entorno:
```bash
export WEBUI_SECRET_KEY="tu-clave-secreta"
export WEBUI_HOST="0.0.0.0"
export WEBUI_PORT="12000"
export OLLAMA_HOST="0.0.0.0:11434"
```

### Personalizar Ubicaci√≥n de Modelos:
```bash
export OLLAMA_MODELS="/ruta/personalizada/modelos"
```

## üö® SOLUCI√ìN DE PROBLEMAS:

### Si OpenWebUI no muestra modelos:
1. Verificar que Ollama est√° ejecut√°ndose: `ps aux | grep ollama`
2. Verificar modelos: `ollama list`
3. Reiniciar OpenWebUI: `pkill -f open-webui && ./start_openwebui.sh`

### Si un modelo es muy lento:
1. Usar modelo m√°s peque√±o (1b en lugar de 3b)
2. Cerrar otros programas
3. Verificar memoria disponible: `free -h`

### Si se queda sin espacio:
1. Eliminar modelos no usados: `ollama rm [modelo]`
2. Verificar espacio: `df -h`

## üìä ESPECIFICACIONES DEL SISTEMA:

- **Python**: 3.11.13 (Conda)
- **OpenWebUI**: v0.6.13
- **Ollama**: v0.9.0
- **Modelos**: 2 instalados (3.3 GB total)
- **Puertos**: 12000 (OpenWebUI), 11434 (Ollama)

## üéâ ¬°INSTALACI√ìN COMPLETADA!

### ‚úÖ Todo Funcionando:
- OpenWebUI instalado y ejecut√°ndose
- Ollama instalado con 2 modelos
- Interfaz web accesible
- Modelos listos para usar
- Scripts de gesti√≥n creados
- Documentaci√≥n completa

### üöÄ Pr√≥ximos Pasos:
1. **Acceder**: https://work-1-pmibcoomalqbelgr.prod-runtime.all-hands.dev
2. **Crear cuenta** de administrador
3. **Seleccionar modelo** (llama3.2:1b o llama3.2:3b)
4. **¬°Comenzar a usar OpenWebUI!**

### üìö Recursos:
- Todas las gu√≠as est√°n en `/workspace/`
- Scripts de gesti√≥n listos para usar
- Logs disponibles para debugging

---

**¬°Disfruta tu nueva instalaci√≥n de OpenWebUI con modelos de IA locales!** üéä